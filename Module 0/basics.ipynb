{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "adN2Vc8ZSeCx"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENROUTER_API\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KmzkuHpT2pP",
        "outputId": "c7ecaedd-93dd-44dd-8328-c6328ca9e8b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENROUTER_API: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "openrouter_api_base = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "openrouter_api_key = os.getenv(\"OPENROUTER_API\")\n",
        "\n",
        "gpt35_chat = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    temperature=0,\n",
        "    openai_api_base=openrouter_api_base,\n",
        "    openai_api_key=openrouter_api_key\n",
        ")\n"
      ],
      "metadata": {
        "id": "dA4Pgr-DUc_p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "msg = HumanMessage(content=\"Hello world\", name=\"Abdullah\")\n",
        "\n",
        "messages = [msg]\n",
        "\n",
        "gpt35_chat.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZvp-YGgWPED",
        "outputId": "58e8f980-e2f3-4aa7-9c3e-3681520bbf5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello Abdullah! How can I assist you today?', additional_kwargs={'refusal': ''}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 13, 'total_tokens': 23, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-37c2f025-fc8d-4e63-b718-c8f3383bff2b-0', usage_metadata={'input_tokens': 13, 'output_tokens': 10, 'total_tokens': 23, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt35_chat.invoke(\"hello world\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Taq193hoW3Zx",
        "outputId": "ea2fda50-f39c-4293-d5bf-b66b5c4d423d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': ''}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'openai/gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-99bb02a4-295b-41b0-8f79-3b71fc3cf08e-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_set_env(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLVdO1ZiW56d",
        "outputId": "58943513-4da9-4600-91eb-528c33ce9d1c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_search = TavilySearchResults(max_results=3)\n",
        "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
      ],
      "metadata": {
        "id": "XbOW7zIvXCiQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA71-poJXHQh",
        "outputId": "571b18a4-3d05-4204-f6fa-5778876170dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.langchain.com/langgraph',\n",
              "  'content': 'LangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.'},\n",
              " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
              "  'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing'},\n",
              " {'url': 'https://towardsdatascience.com/from-basics-to-advanced-exploring-langgraph-e8c1cf4db787',\n",
              "  'content': \"LangGraph is a low-level framework that offers extensive customisation options, allowing you to build precisely what you need. Since LangGraph is built on top of LangChain, it's seamlessly integrated into its ecosystem, making it easy to leverage existing tools and components. However, there are areas where LangGrpah could be improved:\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}